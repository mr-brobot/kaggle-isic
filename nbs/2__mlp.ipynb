{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\"\n",
    "\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES_FILE = DATA_DIR / \"train-image.hdf5\"\n",
    "TRAIN_METADATA_FILE = DATA_DIR / \"train-metadata.csv\"\n",
    "\n",
    "TRAIN_IMAGES_FILE, TRAIN_METADATA_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isic.dataset import ISICDataset\n",
    "\n",
    "ds = ISICDataset(TRAIN_IMAGES_FILE, TRAIN_METADATA_FILE)\n",
    "\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ds:\n",
    "    for i in range(5):\n",
    "        metadata, image, target = ds[i]\n",
    "        print(metadata[\"isic_id\"], target)\n",
    "        image.resize((128, 128)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 128,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"image_size\": 128,\n",
    "    \"threshold\": 0.5,\n",
    "}\n",
    "\n",
    "epochs = params[\"epochs\"]\n",
    "batch_size = params[\"batch_size\"]\n",
    "lr = params[\"learning_rate\"]\n",
    "img_size = params[\"image_size\"], params[\"image_size\"]\n",
    "threshold = params[\"threshold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isic.models import MLP\n",
    "\n",
    "model = MLP(img_size).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\n",
    "    f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = [400666, 393]  # [benign, malignant] from EDA\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(f\"Benign: {class_counts[0]:,} samples\")\n",
    "print(f\"Malignant: {class_counts[1]:,} samples\")\n",
    "print(f\"Imbalance ratio: {class_counts[0] / class_counts[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use weighted BCE loss to handle class imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pos_weight = torch.tensor([ds.pos_weight], device=device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "print(f\"Positive class weight: {ds.pos_weight:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquire datasource resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.open();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from isic.dataset import ImageEncoder, MetadataEncoder, BatchEncoder\n",
    "\n",
    "train_size = int(0.8 * len(ds))\n",
    "val_size = len(ds) - train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    ds, [train_size, val_size], generator=generator\n",
    ")\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "print(f\"Total: {len(ds):,}\")\n",
    "print(f\"Train: {len(train_dataset):,}\")\n",
    "print(f\"Validation: {len(val_dataset):,}\")\n",
    "\n",
    "image_encoder = ImageEncoder(image_size=img_size)\n",
    "metadata_encoder = MetadataEncoder().fit(ds.metadata)\n",
    "batch_encoder = BatchEncoder(\n",
    "    image_encoder=image_encoder,\n",
    "    metadata_encoder=metadata_encoder,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=batch_encoder,\n",
    "    generator=generator,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=batch_encoder,\n",
    ")\n",
    "\n",
    "print(f\"Batches per epoch - Train: {len(train_loader)}, Val: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trackio\n",
    "from isic.training import train, validate, training_summary\n",
    "\n",
    "trackio.init(project=\"mlp\", config=params, embed=False)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # train\n",
    "    train_metrics = train(model, train_loader, criterion, optimizer, device, threshold)\n",
    "\n",
    "    # validate\n",
    "    val_metrics, val_targets, val_predictions = validate(\n",
    "        model, val_loader, criterion, device, threshold\n",
    "    )\n",
    "\n",
    "trackio.finish()\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_summary(val_targets, val_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
